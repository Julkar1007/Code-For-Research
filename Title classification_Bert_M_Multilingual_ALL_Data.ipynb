{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"35a16a9d86f24ccd903478d4328fff45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a21886e836cb42f0a0253359eaa4a3be","IPY_MODEL_ed8cc39791904fcf95402fb899737cbc","IPY_MODEL_a54f067342054bd48d8123bb46dd2d2c"],"layout":"IPY_MODEL_d8b4791231c84fd2a3d5a844dd9070a2"}},"a21886e836cb42f0a0253359eaa4a3be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82352033b6014d929b937a8d964d6171","placeholder":"​","style":"IPY_MODEL_7fd95e509ae841fa805f2985193fbea2","value":"config.json: 100%"}},"ed8cc39791904fcf95402fb899737cbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97673f84d5da46a7bdb965a4a1960bf5","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1be9a2f82944ae8ac003e05b0ab8b77","value":625}},"a54f067342054bd48d8123bb46dd2d2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee62c79a9b9d4ee1a996272c3ce680c0","placeholder":"​","style":"IPY_MODEL_81bcf1ff244047bbaeae8d8813f47b46","value":" 625/625 [00:00&lt;00:00, 26.8kB/s]"}},"d8b4791231c84fd2a3d5a844dd9070a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82352033b6014d929b937a8d964d6171":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fd95e509ae841fa805f2985193fbea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97673f84d5da46a7bdb965a4a1960bf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1be9a2f82944ae8ac003e05b0ab8b77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee62c79a9b9d4ee1a996272c3ce680c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81bcf1ff244047bbaeae8d8813f47b46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30f2af59ccfd449b814ba95cfb199132":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8386fd0384ff40fb92cdea47444d5c56","IPY_MODEL_091f1c03f9d04f58a110a2fdf0336a22","IPY_MODEL_942115bf01114f13b216643a562c58e0"],"layout":"IPY_MODEL_fef272e6755a413d9a38c9b16f36ed2f"}},"8386fd0384ff40fb92cdea47444d5c56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1ca89b0a06f41cfb8b578e267e86cce","placeholder":"​","style":"IPY_MODEL_9a7c29c699ca44e3a1080c6a92af7df7","value":"tokenizer_config.json: 100%"}},"091f1c03f9d04f58a110a2fdf0336a22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d14e73f6752241b7922713589b647fc0","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71cb749991994d36aa1e7609f6b5214e","value":49}},"942115bf01114f13b216643a562c58e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0d2e165b9eb4c108ccbe2eedf973d5f","placeholder":"​","style":"IPY_MODEL_26a6b5c6175446c58cf200722a64c2cc","value":" 49.0/49.0 [00:00&lt;00:00, 1.20kB/s]"}},"fef272e6755a413d9a38c9b16f36ed2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1ca89b0a06f41cfb8b578e267e86cce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a7c29c699ca44e3a1080c6a92af7df7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d14e73f6752241b7922713589b647fc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cb749991994d36aa1e7609f6b5214e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0d2e165b9eb4c108ccbe2eedf973d5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26a6b5c6175446c58cf200722a64c2cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f87431a89e134de0b461c4c207b0dcbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48ab89a8694b45e087f5822f313f1931","IPY_MODEL_254387219bdb4dad9a40ccff46210994","IPY_MODEL_5cbe4eeb504e45dc8647cd6b8ee7e967"],"layout":"IPY_MODEL_0e1bbc54e5db436495c1512c568ccdff"}},"48ab89a8694b45e087f5822f313f1931":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_225bc6d93feb46dd9dda7903ad4f10ce","placeholder":"​","style":"IPY_MODEL_fb012da5556b4cc3b8a387caa702865a","value":"vocab.txt: 100%"}},"254387219bdb4dad9a40ccff46210994":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e59f2028c3f940b6a02711f5a1a2c28f","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5f2509a7eb74b79bc183dc08984accb","value":995526}},"5cbe4eeb504e45dc8647cd6b8ee7e967":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66978eaf6927450abc296eef14f9ed67","placeholder":"​","style":"IPY_MODEL_b1b6dc69765f4baf9bc17b8f18736e50","value":" 996k/996k [00:00&lt;00:00, 1.46MB/s]"}},"0e1bbc54e5db436495c1512c568ccdff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"225bc6d93feb46dd9dda7903ad4f10ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb012da5556b4cc3b8a387caa702865a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e59f2028c3f940b6a02711f5a1a2c28f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5f2509a7eb74b79bc183dc08984accb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66978eaf6927450abc296eef14f9ed67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b6dc69765f4baf9bc17b8f18736e50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dbf1d43cc9a4cf39bd1b88b7fa2882b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54c284382f8b418a98ccc5afaad3ca0c","IPY_MODEL_f2bb57f928ce4997b5dcb33f63de3e21","IPY_MODEL_9ce7af69359d4635866f923f884b23e7"],"layout":"IPY_MODEL_50f796c665d044b7b36ea4a01a94a312"}},"54c284382f8b418a98ccc5afaad3ca0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbbf3626874348959a88a2b493e31153","placeholder":"​","style":"IPY_MODEL_a6952bd2f3d04bd7968c3bc1582bd41c","value":"tokenizer.json: 100%"}},"f2bb57f928ce4997b5dcb33f63de3e21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98a16439a1c84f8989a541e1fbea6639","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7da383984ed344dc8e2b59c267854161","value":1961828}},"9ce7af69359d4635866f923f884b23e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0423d5ad742425b94cb20118a948aca","placeholder":"​","style":"IPY_MODEL_88d999072ccb4cc88cb83fa24914eed7","value":" 1.96M/1.96M [00:00&lt;00:00, 2.22MB/s]"}},"50f796c665d044b7b36ea4a01a94a312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbbf3626874348959a88a2b493e31153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6952bd2f3d04bd7968c3bc1582bd41c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98a16439a1c84f8989a541e1fbea6639":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7da383984ed344dc8e2b59c267854161":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0423d5ad742425b94cb20118a948aca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88d999072ccb4cc88cb83fa24914eed7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c038427e023489a80adbe77bb8e3217":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1cbbd7889ce4096bc36e0379179d80e","IPY_MODEL_3716ba8b61444723ad400ad73d75ac28","IPY_MODEL_76b29c4f00944b1e8012a7a77041f3a1"],"layout":"IPY_MODEL_193a9576725941bd97c67ddbb5092b28"}},"b1cbbd7889ce4096bc36e0379179d80e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d4a56a180924460b5f4f16e9bbd3ed0","placeholder":"​","style":"IPY_MODEL_9a9ec184f5c04eafab95103830b4289e","value":"model.safetensors: 100%"}},"3716ba8b61444723ad400ad73d75ac28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_074f36711e8e414fa5d15261a7ebf62e","max":714290682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4f414b78a1d42c5a0e629daa80e2889","value":714290682}},"76b29c4f00944b1e8012a7a77041f3a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac7acce5053d4b808edf566a397d8935","placeholder":"​","style":"IPY_MODEL_b539f007901f4aaabfb88ce38a6d4fbd","value":" 714M/714M [00:07&lt;00:00, 146MB/s]"}},"193a9576725941bd97c67ddbb5092b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d4a56a180924460b5f4f16e9bbd3ed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a9ec184f5c04eafab95103830b4289e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"074f36711e8e414fa5d15261a7ebf62e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4f414b78a1d42c5a0e629daa80e2889":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac7acce5053d4b808edf566a397d8935":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b539f007901f4aaabfb88ce38a6d4fbd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a924b7035f57443a886fc0e552de45a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e69edf922af4481aaa8c9b840213801b","IPY_MODEL_01bfbeb073e6473a839a1d4d3016ab2e","IPY_MODEL_5d9345048d754fb1a196969ed56ae00c"],"layout":"IPY_MODEL_fe6f6ff1ee8f4418824af078052feff7"}},"e69edf922af4481aaa8c9b840213801b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06057f2eb438445db069b145413a8396","placeholder":"​","style":"IPY_MODEL_e8aff8ee08ae4b4c95c940352534d211","value":"Running tokenizer on dataset: 100%"}},"01bfbeb073e6473a839a1d4d3016ab2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b66880dc1d14e13bac7fece5128cced","max":6150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fe76021dd664e6783d0562cb9b1d7ab","value":6150}},"5d9345048d754fb1a196969ed56ae00c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f526b6b8dc3a43328b713310e5f0bee1","placeholder":"​","style":"IPY_MODEL_18c8fb729a19496d899e8bc70de9a92c","value":" 6150/6150 [00:01&lt;00:00, 3699.41 examples/s]"}},"fe6f6ff1ee8f4418824af078052feff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06057f2eb438445db069b145413a8396":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8aff8ee08ae4b4c95c940352534d211":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b66880dc1d14e13bac7fece5128cced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fe76021dd664e6783d0562cb9b1d7ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f526b6b8dc3a43328b713310e5f0bee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18c8fb729a19496d899e8bc70de9a92c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c378b3b567e44ec79d7b73c240b4bfac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ab06813011c45bd9a869a918debbfee","IPY_MODEL_3c0bd83506c34efaa93a8df5d910b842","IPY_MODEL_d12fd5f61bbb483ab4a70d8c3e0e3086"],"layout":"IPY_MODEL_86251485570d478aa2ccf45fdb1cf49f"}},"3ab06813011c45bd9a869a918debbfee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_267a77b3ef394718a8e02a1b46caf68a","placeholder":"​","style":"IPY_MODEL_28ad338bb6244c4d97897b34edf15558","value":"Downloading builder script: 100%"}},"3c0bd83506c34efaa93a8df5d910b842":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40a76c9cb8e047159657af38d7d55ffd","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12204494fda04c009d9751524e41ca1b","value":4203}},"d12fd5f61bbb483ab4a70d8c3e0e3086":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d12d432717274dea96880d9e5386a55e","placeholder":"​","style":"IPY_MODEL_5a7980db229b49af9d8ebfa1b44502ff","value":" 4.20k/4.20k [00:00&lt;00:00, 152kB/s]"}},"86251485570d478aa2ccf45fdb1cf49f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"267a77b3ef394718a8e02a1b46caf68a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28ad338bb6244c4d97897b34edf15558":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40a76c9cb8e047159657af38d7d55ffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12204494fda04c009d9751524e41ca1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d12d432717274dea96880d9e5386a55e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7980db229b49af9d8ebfa1b44502ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ee85cba25554da0aa6baadbe285495f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab5fb01067a94f8d9b6dbd3144460ddb","IPY_MODEL_1485d717fca341c1bb81a318bd21e648","IPY_MODEL_9b408d1bc899454a8f310ccad3dccb24"],"layout":"IPY_MODEL_c74233e9cf2848f6b3e0b0e37a1bce70"}},"ab5fb01067a94f8d9b6dbd3144460ddb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fffef0f1f524e3caaea0fdcd1ff5cb9","placeholder":"​","style":"IPY_MODEL_182def3c6b674d6b88882f40b1134673","value":"Map: 100%"}},"1485d717fca341c1bb81a318bd21e648":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2842aa18f172483bbd2b8bbdbc2e50bb","max":4920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52dd4ddadcfc448ca5ee2dd761a7c6ce","value":4920}},"9b408d1bc899454a8f310ccad3dccb24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed805fb2900f44f3ba573b38bde1ef3d","placeholder":"​","style":"IPY_MODEL_2c4b926bf562483b9bd09feef42f8ce7","value":" 4920/4920 [00:06&lt;00:00, 908.54 examples/s]"}},"c74233e9cf2848f6b3e0b0e37a1bce70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fffef0f1f524e3caaea0fdcd1ff5cb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"182def3c6b674d6b88882f40b1134673":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2842aa18f172483bbd2b8bbdbc2e50bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52dd4ddadcfc448ca5ee2dd761a7c6ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed805fb2900f44f3ba573b38bde1ef3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c4b926bf562483b9bd09feef42f8ce7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3643a570ed404b308cb6cdbc6fe8bdc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9c9ab2d2bcb457aa3433c9120684fb2","IPY_MODEL_a7a9aead894a4c5e9a02832a26853ccb","IPY_MODEL_bc7428385d464e0d94dc46e48e85b53d"],"layout":"IPY_MODEL_66dced8679c548759c196e92413c47da"}},"b9c9ab2d2bcb457aa3433c9120684fb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71ea1084a13b4befa87a137283f330a4","placeholder":"​","style":"IPY_MODEL_4ad96781f67745ab8ec85b02ea8b46d8","value":"Map: 100%"}},"a7a9aead894a4c5e9a02832a26853ccb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37d1432c4fcb4e74b2a89eb47e91d01f","max":1230,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff8b250d7a284c8aac11d33a05c5727c","value":1230}},"bc7428385d464e0d94dc46e48e85b53d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_437d799b555741c98c545a8066c68104","placeholder":"​","style":"IPY_MODEL_f61c96d089464eaaad1a752cc6f8af8d","value":" 1230/1230 [00:00&lt;00:00, 1623.28 examples/s]"}},"66dced8679c548759c196e92413c47da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71ea1084a13b4befa87a137283f330a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ad96781f67745ab8ec85b02ea8b46d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37d1432c4fcb4e74b2a89eb47e91d01f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff8b250d7a284c8aac11d33a05c5727c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"437d799b555741c98c545a8066c68104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f61c96d089464eaaad1a752cc6f8af8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KL2xa86bbyCD","executionInfo":{"status":"ok","timestamp":1732889403877,"user_tz":-360,"elapsed":3868,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"bfca67cb-d5c2-4ff6-de3c-0462e97c66ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install evaluate\n","!pip install --upgrade accelerate\n","!pip install --upgrade wandb\n"],"metadata":{"id":"b855HOsgIxIv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732889423808,"user_tz":-360,"elapsed":19937,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"2433fbf6-78c8-4c97-95cc-b4a9fc6a8631"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n","Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]}]},{"cell_type":"code","source":["import logging\n","import os\n","import random\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Optional\n","import pandas as pd\n","import datasets\n","import evaluate\n","import numpy as np\n","from datasets import load_dataset, Dataset, DatasetDict\n","import torch\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    PretrainedConfig,\n","    Trainer,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version, send_example_telemetry\n","from transformers.utils.versions import require_version\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","    datefmt=\"%m/%d/%Y %H:%M:%S\",\n","    handlers=[logging.StreamHandler(sys.stdout)],\n",")"],"metadata":{"id":"WZyzuxKbcNjI","executionInfo":{"status":"ok","timestamp":1732889423808,"user_tz":-360,"elapsed":10,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":8,"outputs":[]},{"source":["import pandas as pd # Import the pandas library and assign it to the alias 'pd'\n","df = pd.read_csv(\"/content/drive/MyDrive/My_Research/Newspaper/Title_Classification/Dataset/NewspaperDataFinalVersion - Sports (1).csv\")"],"cell_type":"code","metadata":{"id":"VITEkT8Tsfsg","executionInfo":{"status":"ok","timestamp":1732889425358,"user_tz":-360,"elapsed":1559,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df=df.drop(['Paper Name','Date'], axis=1)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ouGF78YGceYc","executionInfo":{"status":"ok","timestamp":1732889425370,"user_tz":-360,"elapsed":42,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"6c7748ec-350e-4cfd-f477-b7d3a1090555"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                 Title Category\n","0                দিনজুড়ে বোলিংয়ে হতাশা   Sports\n","1  আবারও ছাদখোলা বাসে উৎসবের প্রতিজ্ঞা   Sports\n","2       নিজেদের ব্যাটিংয়ে চোখ সিমন্সের   Sports\n","3      ইস্টবেঙ্গলের কাছে বড় হার কিংসের   Sports\n","4       মূল আলোচ্য নাজমুলের অধিনায়কত্ব   Sports"],"text/html":["\n","  <div id=\"df-7d02dc4f-270e-4d94-9b9c-9ca12bd87b87\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>দিনজুড়ে বোলিংয়ে হতাশা</td>\n","      <td>Sports</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>আবারও ছাদখোলা বাসে উৎসবের প্রতিজ্ঞা</td>\n","      <td>Sports</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>নিজেদের ব্যাটিংয়ে চোখ সিমন্সের</td>\n","      <td>Sports</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ইস্টবেঙ্গলের কাছে বড় হার কিংসের</td>\n","      <td>Sports</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>মূল আলোচ্য নাজমুলের অধিনায়কত্ব</td>\n","      <td>Sports</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d02dc4f-270e-4d94-9b9c-9ca12bd87b87')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7d02dc4f-270e-4d94-9b9c-9ca12bd87b87 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7d02dc4f-270e-4d94-9b9c-9ca12bd87b87');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b4f4c6dc-5803-413e-8e1c-edea5c0f203a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4f4c6dc-5803-413e-8e1c-edea5c0f203a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b4f4c6dc-5803-413e-8e1c-edea5c0f203a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 6150,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6059,\n        \"samples\": [\n          \"\\u099c\\u09c0\\u09ac\\u09bf\\u09a4\\u09c7\\u09b0 \\u09a6\\u09c7\\u09b9\\u09c7 '\\u09ae\\u09c3\\u09a4' \\u09ac\\u09cd\\u09af\\u0995\\u09cd\\u09a4\\u09bf\\u09b0 \\u09b9\\u09be\\u09a4\",\n          \"\\u0995\\u09be\\u09b0\\u09be\\u09ac\\u09be\\u0996\\u09c7 \\u09ab\\u09c7\\u09b0 \\u0985\\u09ad\\u09bf\\u09af\\u09be\\u09a8 \\u09b6\\u09c1\\u09b0\\u09c1 \\u0986\\u099c\\u09be\\u09b0\\u09ac\\u09be\\u0987\\u099c\\u09be\\u09a8\\u09c7\\u09b0\",\n          \"\\u09b6\\u09b8\\u09cd\\u09af \\u099a\\u09c1\\u0995\\u09cd\\u09a4\\u09bf \\u09a5\\u09c7\\u0995\\u09c7 \\u09ac\\u09c7\\u09b0\\u09bf\\u09df\\u09c7 \\u0997\\u09c7\\u09b2 \\u09b0\\u09be\\u09b6\\u09bf\\u09df\\u09be\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Sports\",\n          \"International\",\n          \"National\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df.columns=[\"Title\",\"Category\"]"],"metadata":{"id":"huyynLT2chDk","executionInfo":{"status":"ok","timestamp":1732889425371,"user_tz":-360,"elapsed":38,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    learning_rate=2e-5,\n","    num_train_epochs=5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    output_dir=\"./bertBaseMultilingualNew/\",\n","    overwrite_output_dir=True,\n","    remove_unused_columns=False,\n","    local_rank= 1,\n","    load_best_model_at_end=True,\n","    save_total_limit=2,\n","    save_strategy=\"no\"\n",")\n","\n","max_train_samples = None\n","max_eval_samples=None\n","max_predict_samples=None\n","max_seq_length = 512\n","batch_size = 16"],"metadata":{"id":"GOlucbnIc-_E","executionInfo":{"status":"ok","timestamp":1732889425371,"user_tz":-360,"elapsed":36,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["transformers.utils.logging.set_verbosity_info()\n","\n","log_level = training_args.get_process_log_level()\n","logger.setLevel(log_level)\n","datasets.utils.logging.set_verbosity(log_level)\n","transformers.utils.logging.set_verbosity(log_level)\n","transformers.utils.logging.enable_default_handler()\n","transformers.utils.logging.enable_explicit_format()\n","logger.warning(\n","    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n","    + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",")\n","logger.info(f\"Training/evaluation parameters {training_args}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kgf-6S6CdBqc","executionInfo":{"status":"ok","timestamp":1732889425371,"user_tz":-360,"elapsed":35,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"4351d0b1-4177-4ce6-842f-3b0ffd8efbb2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=False,\n","do_predict=False,\n","do_train=False,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-05,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=./bertBaseMultilingualNew/runs/Nov29_14-10-22_79c436fb4397,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=5,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=./bertBaseMultilingualNew/,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=16,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=./bertBaseMultilingualNew/,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=no,\n","save_total_limit=2,\n","seed=42,\n","skip_memory_metrics=True,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n"]}]},{"cell_type":"code","source":["model_name = 'bert-base-multilingual-cased'"],"metadata":{"id":"DCKIMnImdF18","executionInfo":{"status":"ok","timestamp":1732889425371,"user_tz":-360,"elapsed":28,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["set_seed(training_args.seed)"],"metadata":{"id":"CRh9t5-FdH-U","executionInfo":{"status":"ok","timestamp":1732889425371,"user_tz":-360,"elapsed":27,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["punctuations = [\"|\",\"‘\",\">\",\"<\",\"*\",   \"।\", \",\", \";\", \":\", \"?\", \"!\", \"'\", \".\", \"\\\"\", \"-\",\n","                \"[\", \"]\", \"{\", \"}\", \"(\", \")\", '–', \"—\", \"―\", \"~\"]\n","\n","def remove_url(word):\n","  return word.split(\"http\")[0].strip()\n","\n","def extreme_process(word):\n","  word_list = [word]\n","  splitter_list = [\"**\",\"*\", \"…\", \"-\"]\n","\n","  for i in splitter_list:\n","    if i in word:\n","      temp_list = word.split(i)\n","      word_list = list(filter(lambda x:x.strip() != \"\", temp_list))\n","      return word_list\n","  return word_list\n","\n","\n","def process_word(word):\n","  word = word.strip()\n","  if len(word) == 0:\n","    return []\n","  elif len(word) == 1:\n","    if word not in punctuations:\n","      return [word]\n","    else:\n","      return []\n","  else:\n","    word = remove_url(word)\n","\n","    if len(word) == 0:\n","      return []\n","    elif len(word) == 1:\n","      if word in punctuations:\n","        return []\n","      else:\n","        return [word]\n","    else:\n","      if word[0] in punctuations:\n","        word = word[1:]\n","      if word[-1] in punctuations:\n","        word = word[:-1]\n","\n","      word = extreme_process(word)\n","\n","      return word\n"],"metadata":{"id":"ExED3bssdKFc","executionInfo":{"status":"ok","timestamp":1732889425371,"user_tz":-360,"elapsed":26,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","l2id = {'Sports': 2, 'National': 1, 'International': 0}\n","newdf = df\n","print(newdf.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fX5IZDNMdPbs","executionInfo":{"status":"ok","timestamp":1732889425371,"user_tz":-360,"elapsed":25,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"7c2e6131-e98d-43f0-d29d-69bf7d4bee07"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["                                 Title Category\n","0                দিনজুড়ে বোলিংয়ে হতাশা   Sports\n","1  আবারও ছাদখোলা বাসে উৎসবের প্রতিজ্ঞা   Sports\n","2       নিজেদের ব্যাটিংয়ে চোখ সিমন্সের   Sports\n","3      ইস্টবেঙ্গলের কাছে বড় হার কিংসের   Sports\n","4       মূল আলোচ্য নাজমুলের অধিনায়কত্ব   Sports\n"]}]},{"cell_type":"code","source":["for index, row in newdf.iterrows():\n","  unprocessed_spliited_word = row[\"Title\"].split(\" \")\n","  processed_word_list = []\n","  for i in unprocessed_spliited_word:\n","    processed_word_list += process_word(i)\n","  newdf.at[index, \"Title\"] = \" \".join(processed_word_list)"],"metadata":{"id":"Y8-R2wT2dU3c","executionInfo":{"status":"ok","timestamp":1732889426048,"user_tz":-360,"elapsed":699,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["newdf['Category'] = newdf['Category'].map(l2id)\n","print(newdf.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZ70w5UXdYCk","executionInfo":{"status":"ok","timestamp":1732889426048,"user_tz":-360,"elapsed":28,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"e5baff30-e25a-4837-b017-6bf549a45ff7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["                                 Title  Category\n","0                দিনজুড়ে বোলিংয়ে হতাশা         2\n","1  আবারও ছাদখোলা বাসে উৎসবের প্রতিজ্ঞা         2\n","2       নিজেদের ব্যাটিংয়ে চোখ সিমন্সের         2\n","3      ইস্টবেঙ্গলের কাছে বড় হার কিংসের         2\n","4       মূল আলোচ্য নাজমুলের অধিনায়কত্ব         2\n"]}]},{"cell_type":"code","source":["newdf = Dataset.from_pandas(newdf)\n","print(newdf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FappAxaxdcY8","executionInfo":{"status":"ok","timestamp":1732889426048,"user_tz":-360,"elapsed":24,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"32881721-35fb-496c-9827-37191b5a750c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['Title', 'Category'],\n","    num_rows: 6150\n","})\n"]}]},{"cell_type":"code","source":["raw_datasets = DatasetDict(\n","    {\"train\": newdf,}\n",")"],"metadata":{"id":"Yc-5aU5YfNc0","executionInfo":{"status":"ok","timestamp":1732889426048,"user_tz":-360,"elapsed":20,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["label_list = raw_datasets[\"train\"].unique(\"Category\")\n","print(label_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxHmP_94fRZE","executionInfo":{"status":"ok","timestamp":1732889426048,"user_tz":-360,"elapsed":19,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"d4ceaf12-35d1-4e8e-f415-23b83b1e5428"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 0, 1]\n"]}]},{"cell_type":"code","source":["label_list.sort()  # sort the labels for determine\n","print(label_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZOrpkBnfT8E","executionInfo":{"status":"ok","timestamp":1732889426048,"user_tz":-360,"elapsed":15,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"2bbd4608-363a-4fac-f1a1-e7e3f19c7b2c"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 1, 2]\n"]}]},{"cell_type":"code","source":["num_labels = len(label_list)\n","print(num_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWre7d28feAL","executionInfo":{"status":"ok","timestamp":1732889426048,"user_tz":-360,"elapsed":11,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"1cdfb2f6-7b7a-4b07-d045-10aec56a808d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n"]}]},{"cell_type":"code","source":["config = AutoConfig.from_pretrained(\n","    model_name,\n","    num_labels=num_labels,\n","    finetuning_task=None,\n","    cache_dir=None,\n","    revision=\"main\",\n","    use_auth_token=None,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":902,"referenced_widgets":["35a16a9d86f24ccd903478d4328fff45","a21886e836cb42f0a0253359eaa4a3be","ed8cc39791904fcf95402fb899737cbc","a54f067342054bd48d8123bb46dd2d2c","d8b4791231c84fd2a3d5a844dd9070a2","82352033b6014d929b937a8d964d6171","7fd95e509ae841fa805f2985193fbea2","97673f84d5da46a7bdb965a4a1960bf5","f1be9a2f82944ae8ac003e05b0ab8b77","ee62c79a9b9d4ee1a996272c3ce680c0","81bcf1ff244047bbaeae8d8813f47b46"]},"id":"kZ4zgq2cfahz","executionInfo":{"status":"ok","timestamp":1732889428063,"user_tz":-360,"elapsed":2023,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"db210f9f-2049-4e3c-8bc8-a57e3ad4fabc"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a16a9d86f24ccd903478d4328fff45"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:679] 2024-11-29 14:10:26,167 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n","[INFO|configuration_utils.py:746] 2024-11-29 14:10:26,177 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.46.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\n","    model_name,\n","    cache_dir=None,\n","    use_fast=True,\n","    revision=\"main\",\n","    use_auth_token=None,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["30f2af59ccfd449b814ba95cfb199132","8386fd0384ff40fb92cdea47444d5c56","091f1c03f9d04f58a110a2fdf0336a22","942115bf01114f13b216643a562c58e0","fef272e6755a413d9a38c9b16f36ed2f","f1ca89b0a06f41cfb8b578e267e86cce","9a7c29c699ca44e3a1080c6a92af7df7","d14e73f6752241b7922713589b647fc0","71cb749991994d36aa1e7609f6b5214e","e0d2e165b9eb4c108ccbe2eedf973d5f","26a6b5c6175446c58cf200722a64c2cc","f87431a89e134de0b461c4c207b0dcbb","48ab89a8694b45e087f5822f313f1931","254387219bdb4dad9a40ccff46210994","5cbe4eeb504e45dc8647cd6b8ee7e967","0e1bbc54e5db436495c1512c568ccdff","225bc6d93feb46dd9dda7903ad4f10ce","fb012da5556b4cc3b8a387caa702865a","e59f2028c3f940b6a02711f5a1a2c28f","a5f2509a7eb74b79bc183dc08984accb","66978eaf6927450abc296eef14f9ed67","b1b6dc69765f4baf9bc17b8f18736e50","1dbf1d43cc9a4cf39bd1b88b7fa2882b","54c284382f8b418a98ccc5afaad3ca0c","f2bb57f928ce4997b5dcb33f63de3e21","9ce7af69359d4635866f923f884b23e7","50f796c665d044b7b36ea4a01a94a312","dbbf3626874348959a88a2b493e31153","a6952bd2f3d04bd7968c3bc1582bd41c","98a16439a1c84f8989a541e1fbea6639","7da383984ed344dc8e2b59c267854161","e0423d5ad742425b94cb20118a948aca","88d999072ccb4cc88cb83fa24914eed7"]},"id":"N8U4yDnRfhra","executionInfo":{"status":"ok","timestamp":1732889433124,"user_tz":-360,"elapsed":5073,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"e9c2eb0f-ba47-4b93-d5ba-45963ea363b8"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f2af59ccfd449b814ba95cfb199132"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:679] 2024-11-29 14:10:26,729 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n","[INFO|configuration_utils.py:746] 2024-11-29 14:10:26,734 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.46.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87431a89e134de0b461c4c207b0dcbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dbf1d43cc9a4cf39bd1b88b7fa2882b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|tokenization_utils_base.py:2211] 2024-11-29 14:10:29,867 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/vocab.txt\n","[INFO|tokenization_utils_base.py:2211] 2024-11-29 14:10:29,875 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer.json\n","[INFO|tokenization_utils_base.py:2211] 2024-11-29 14:10:29,879 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2211] 2024-11-29 14:10:29,883 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:2211] 2024-11-29 14:10:29,886 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer_config.json\n","[INFO|configuration_utils.py:679] 2024-11-29 14:10:29,889 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n","[INFO|configuration_utils.py:746] 2024-11-29 14:10:29,894 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.46.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]}]},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    from_tf=bool(\".ckpt\" in model_name),\n","    config=config,\n","    cache_dir=None,\n","    revision=\"main\",\n","    use_auth_token=None,\n","    ignore_mismatched_sizes=False,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8c038427e023489a80adbe77bb8e3217","b1cbbd7889ce4096bc36e0379179d80e","3716ba8b61444723ad400ad73d75ac28","76b29c4f00944b1e8012a7a77041f3a1","193a9576725941bd97c67ddbb5092b28","3d4a56a180924460b5f4f16e9bbd3ed0","9a9ec184f5c04eafab95103830b4289e","074f36711e8e414fa5d15261a7ebf62e","b4f414b78a1d42c5a0e629daa80e2889","ac7acce5053d4b808edf566a397d8935","b539f007901f4aaabfb88ce38a6d4fbd"]},"id":"r6a0oFEEfkzC","executionInfo":{"status":"ok","timestamp":1732889443004,"user_tz":-360,"elapsed":9889,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"61b069e4-bc65-429a-af7b-ce2167bd4373"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c038427e023489a80adbe77bb8e3217"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|modeling_utils.py:3937] 2024-11-29 14:10:40,224 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/model.safetensors\n","[INFO|logging.py:343] 2024-11-29 14:10:40,438 >> A pretrained model of type `BertForSequenceClassification` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n","* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n","* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n","* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n","* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n","If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n","[INFO|modeling_utils.py:4790] 2024-11-29 14:10:40,517 >> Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:4802] 2024-11-29 14:10:40,519 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["non_label_column_names = [name for name in raw_datasets[\"train\"].column_names if name != \"Category\"]\n","print(non_label_column_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"siG0JnrCfwOc","executionInfo":{"status":"ok","timestamp":1732889443005,"user_tz":-360,"elapsed":62,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"2af3127e-0592-47ef-bbaa-4e8f0dbc13a0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["['Title']\n"]}]},{"cell_type":"code","source":["sentence_key= non_label_column_names[0]\n","print(sentence_key)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYRt5DKVfzql","executionInfo":{"status":"ok","timestamp":1732889443005,"user_tz":-360,"elapsed":57,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"494fa832-2839-4d12-ba55-4c307c322595"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Title\n"]}]},{"cell_type":"code","source":["padding = \"max_length\"\n","label_to_id = None\n","\n","if (model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id):\n","    # Some have all caps in their config, some don't.\n","    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n","    if sorted(label_name_to_id.keys()) == sorted(label_list):\n","        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n","    else:\n","        logger.warning(\n","            \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n","            f\"model labels: {sorted(label_name_to_id.keys())}, dataset labels: {sorted(label_list)}.\"\n","            \"\\nIgnoring the model labels as a result.\",)"],"metadata":{"id":"tJfpdg0if4M0","executionInfo":{"status":"ok","timestamp":1732889443005,"user_tz":-360,"elapsed":49,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["if label_to_id is not None:\n","    model.config.label2id = label_to_id\n","    model.config.id2label = {id: label for label, id in config.label2id.items()}"],"metadata":{"id":"61AEhGXaf57s","executionInfo":{"status":"ok","timestamp":1732889443005,"user_tz":-360,"elapsed":47,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["if 128 > tokenizer.model_max_length:\n","    logger.warning(\n","        f\"The max_seq_length passed ({128}) is larger than the maximum length for the\"\n","        f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\")"],"metadata":{"id":"M4Vbhbguf7w8","executionInfo":{"status":"ok","timestamp":1732889443005,"user_tz":-360,"elapsed":46,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["max_seq_length = min(128, tokenizer.model_max_length)\n","print(max_seq_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjRC7949f-nO","executionInfo":{"status":"ok","timestamp":1732889443005,"user_tz":-360,"elapsed":45,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"6d3b5cdc-711a-4d82-a96d-e8175ab44741"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["128\n"]}]},{"cell_type":"code","source":["def preprocess_function(examples):\n","    # Tokenize the texts\n","    args = (\n","        (examples[sentence_key],))\n","    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n","\n","    # Map labels to IDs (not necessary for GLUE tasks)\n","    if label_to_id is not None and \"label\" in examples:\n","        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n","    return result"],"metadata":{"id":"gIoJm46kgA50","executionInfo":{"status":"ok","timestamp":1732889443005,"user_tz":-360,"elapsed":38,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["raw_datasets = raw_datasets.map(\n","    preprocess_function,\n","    batched=True,\n","    load_from_cache_file=True,\n","    desc=\"Running tokenizer on dataset\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["a924b7035f57443a886fc0e552de45a1","e69edf922af4481aaa8c9b840213801b","01bfbeb073e6473a839a1d4d3016ab2e","5d9345048d754fb1a196969ed56ae00c","fe6f6ff1ee8f4418824af078052feff7","06057f2eb438445db069b145413a8396","e8aff8ee08ae4b4c95c940352534d211","4b66880dc1d14e13bac7fece5128cced","9fe76021dd664e6783d0562cb9b1d7ab","f526b6b8dc3a43328b713310e5f0bee1","18c8fb729a19496d899e8bc70de9a92c"]},"id":"ONpeI2kbgCP8","executionInfo":{"status":"ok","timestamp":1732889445243,"user_tz":-360,"elapsed":2275,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"052c8b81-4af4-425a-ddc5-2f9a4a6461ad"},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":["Running tokenizer on dataset:   0%|          | 0/6150 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a924b7035f57443a886fc0e552de45a1"}},"metadata":{}}]},{"cell_type":"code","source":["if \"train\" not in raw_datasets:\n","    raise ValueError(\"requires a train dataset\")"],"metadata":{"id":"O-_uJRN_gGrL","executionInfo":{"status":"ok","timestamp":1732889445243,"user_tz":-360,"elapsed":25,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["train_dataset = raw_datasets[\"train\"]\n","print(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H60MZjFNgIJr","executionInfo":{"status":"ok","timestamp":1732889445244,"user_tz":-360,"elapsed":25,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"354f8b75-987a-4d31-f374-a5e1c4cf1dd5"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['Title', 'Category', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 6150\n","})\n"]}]},{"cell_type":"code","source":["print(max_predict_samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gMLHGBvgKQU","executionInfo":{"status":"ok","timestamp":1732889445245,"user_tz":-360,"elapsed":22,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"fdecef64-ab7e-41ad-9e4f-6675bbec5b52"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["if max_predict_samples is not None:\n","    max_predict_samples_n = min(len(predict_dataset), max_predict_samples)\n","    predict_dataset = predict_dataset.select(range(max_predict_samples_n))"],"metadata":{"id":"IeuA9JdsgS9T","executionInfo":{"status":"ok","timestamp":1732889445245,"user_tz":-360,"elapsed":17,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["for index in random.sample(range(len(train_dataset)), 3):\n","    logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGHwukiWgVH8","executionInfo":{"status":"ok","timestamp":1732889445245,"user_tz":-360,"elapsed":16,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"a4d36480-00bb-41fd-99c2-211c55ea692d"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:__main__:Sample 5238 of the training set: {'Title': 'থুনবার্গকে জরিমানা করলেন আদালত', 'Category': 0, 'input_ids': [101, 964, 64437, 36213, 88213, 18243, 955, 82742, 29454, 12079, 948, 11128, 28799, 11737, 938, 106352, 13458, 13542, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","INFO:__main__:Sample 912 of the training set: {'Title': 'সকালে মাঠে নামছে ব্রাজিল রাতে ফ্রান্স', 'Category': 2, 'input_ids': [101, 978, 80180, 18601, 90534, 35059, 32294, 970, 21790, 100277, 62753, 974, 65383, 969, 21790, 18770, 27556, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","INFO:__main__:Sample 204 of the training set: {'Title': 'ঘুরে দাঁড়ানোর মিশনে বার্সা সিটি', 'Category': 2, 'input_ids': [101, 951, 29261, 11199, 100, 972, 102916, 30023, 17660, 11128, 27556, 12079, 978, 76614, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n"]}]},{"cell_type":"code","source":["metric = evaluate.load(\"accuracy\")"],"metadata":{"id":"vE_IGANmgXdc","executionInfo":{"status":"ok","timestamp":1732889447042,"user_tz":-360,"elapsed":1807,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c378b3b567e44ec79d7b73c240b4bfac","3ab06813011c45bd9a869a918debbfee","3c0bd83506c34efaa93a8df5d910b842","d12fd5f61bbb483ab4a70d8c3e0e3086","86251485570d478aa2ccf45fdb1cf49f","267a77b3ef394718a8e02a1b46caf68a","28ad338bb6244c4d97897b34edf15558","40a76c9cb8e047159657af38d7d55ffd","12204494fda04c009d9751524e41ca1b","d12d432717274dea96880d9e5386a55e","5a7980db229b49af9d8ebfa1b44502ff"]},"outputId":"649b4065-971b-430f-89a9-3e8d6ab9a2b9"},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c378b3b567e44ec79d7b73c240b4bfac"}},"metadata":{}}]},{"cell_type":"code","source":["def calculate_micro_f1_score(true_positives, false_positives, false_negatives):\n","    total_tp = sum(true_positives)\n","    total_fp = sum(false_positives)\n","    total_fn = sum(false_negatives)\n","\n","    micro_precision = total_tp / (total_tp + total_fp + 1e-9)\n","    micro_recall = total_tp / (total_tp + total_fn + 1e-9)\n","\n","    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall + 1e-9)\n","\n","    return micro_f1"],"metadata":{"id":"1UBAQh8WgcjM","executionInfo":{"status":"ok","timestamp":1732889447043,"user_tz":-360,"elapsed":14,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(p):\n","    \"\"\"\n","    Calculates and returns a dictionary of metrics (accuracy, precision, recall, f1)\n","    for a given prediction set.\n","\n","    Args:\n","        p: EvalPrediction object containing predictions and label_ids.\n","\n","    Returns:\n","        Dictionary of metrics.\n","    \"\"\"\n","\n","    # Get predictions and labels\n","    preds = np.argmax(p.predictions, axis=1)  # Assuming predictions are logits\n","    labels = p.label_ids\n","\n","    # Convert labels to float32\n","    labels = labels.astype(np.float32)\n","\n","    # Assuming your model outputs logits and you have a fixed number of labels\n","    num_labels = len(np.unique(labels))  # Infer the number of labels from the data\n","    # or\n","    # num_labels = 5 # Assign num_labels to number of classes in your dataset if known before runtime.\n","\n","    # Initialize dictionaries to store TP, FP, and FN for each class\n","    true_positives = {label: 0 for label in range(num_labels)}\n","    false_positives = {label: 0 for label in range(num_labels)}\n","    false_negatives = {label: 0 for label in range(num_labels)}\n","\n","    # Calculate TP, FP, and FN for each class\n","    for prediction, true_label in zip(preds, labels):\n","        if prediction == true_label:\n","            true_positives[true_label] += 1\n","        else:\n","            false_positives[prediction] += 1\n","            false_negatives[true_label] += 1\n","\n","    # Calculate overall accuracy\n","    accuracy = np.sum(preds == labels) / len(labels)\n","\n","    # Calculate precision, recall, and F1 score for each class\n","    precision = {}\n","    recall = {}\n","    f1 = {}\n","\n","    for label in range(num_labels):\n","        # Avoid division by zero if there are no predictions or true labels for a class\n","        if true_positives[label] + false_positives[label] == 0:\n","            precision[label] = 0.0\n","        else:\n","            precision[label] = true_positives[label] / (true_positives[label] + false_positives[label])\n","\n","        if true_positives[label] + false_negatives[label] == 0:\n","            recall[label] = 0.0\n","        else:\n","            recall[label] = true_positives[label] / (true_positives[label] + false_negatives[label])\n","\n","        if precision[label] + recall[label] == 0:\n","            f1[label] = 0.0\n","        else:\n","            f1[label] = 2 * (precision[label] * recall[label]) / (precision[label] + recall[label])\n","\n","    # Calculate macro-averaged precision, recall, and F1 score\n","    macro_precision = np.mean(list(precision.values()))\n","    macro_recall = np.mean(list(recall.values()))\n","    macro_f1 = np.mean(list(f1.values()))\n","\n","    # Return the metrics\n","    return {\n","        \"accuracy\": accuracy,\n","        \"macro_precision\": macro_precision,\n","        \"macro_recall\": macro_recall,\n","        \"macro_f1\": macro_f1,\n","    }"],"metadata":{"id":"GqhFJjgrgidk","executionInfo":{"status":"ok","timestamp":1732889447043,"user_tz":-360,"elapsed":13,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["data_collator = default_data_collator"],"metadata":{"id":"U-GBzJxJglNz","executionInfo":{"status":"ok","timestamp":1732889447043,"user_tz":-360,"elapsed":12,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import numpy as np\n","from datasets import Dataset\n","\n","# Convert the Hugging Face Dataset to a NumPy array or list\n","# Assuming your dataset has a column named 'Title' and 'Category'\n","train_Titles = train_dataset[\"Title\"]\n","train_Categorys = train_dataset[\"Category\"]\n","\n","# Now you can use train_test_split\n","train_Titles, eval_Titles, train_Categorys, eval_Categorys = train_test_split(\n","    train_Titles, train_Categorys, test_size=0.2, random_state=42\n",")\n","\n","# Create new Hugging Face Datasets from the split data, renaming 'Category' to 'labels'\n","train_dataset = Dataset.from_dict({\"Title\": train_Titles, \"labels\": train_Categorys})\n","eval_dataset = Dataset.from_dict({\"Title\": eval_Titles, \"labels\": eval_Categorys})\n","\n","\n","def preprocess_function(examples):\n","    # Tokenize the texts\n","    return tokenizer(examples[\"Title\"], padding=\"max_length\", truncation=True)\n","\n","# Apply the preprocessing function to your datasets\n","train_dataset = train_dataset.map(preprocess_function, batched=True)\n","eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,  # Pass the training dataset to the trainer\n","    eval_dataset=eval_dataset,  # Pass the validation dataset to the trainer\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["4ee85cba25554da0aa6baadbe285495f","ab5fb01067a94f8d9b6dbd3144460ddb","1485d717fca341c1bb81a318bd21e648","9b408d1bc899454a8f310ccad3dccb24","c74233e9cf2848f6b3e0b0e37a1bce70","8fffef0f1f524e3caaea0fdcd1ff5cb9","182def3c6b674d6b88882f40b1134673","2842aa18f172483bbd2b8bbdbc2e50bb","52dd4ddadcfc448ca5ee2dd761a7c6ce","ed805fb2900f44f3ba573b38bde1ef3d","2c4b926bf562483b9bd09feef42f8ce7","3643a570ed404b308cb6cdbc6fe8bdc6","b9c9ab2d2bcb457aa3433c9120684fb2","a7a9aead894a4c5e9a02832a26853ccb","bc7428385d464e0d94dc46e48e85b53d","66dced8679c548759c196e92413c47da","71ea1084a13b4befa87a137283f330a4","4ad96781f67745ab8ec85b02ea8b46d8","37d1432c4fcb4e74b2a89eb47e91d01f","ff8b250d7a284c8aac11d33a05c5727c","437d799b555741c98c545a8066c68104","f61c96d089464eaaad1a752cc6f8af8d"]},"id":"_WW2CSlPgzB8","executionInfo":{"status":"ok","timestamp":1732889456514,"user_tz":-360,"elapsed":9483,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"edeaa834-fcc2-47d2-fedf-b03542333740"},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4920 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee85cba25554da0aa6baadbe285495f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1230 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3643a570ed404b308cb6cdbc6fe8bdc6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-45-571c33f6d8ae>:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]}]},{"cell_type":"code","source":["import os\n","#os.environ[\"WANDB_START_TIMEOUT\"] = \"300\"  # Example: 300 seconds\n","os.environ[\"WANDB_DISABLED\"] = \"true\""],"metadata":{"id":"3HPFPHi8u1no","executionInfo":{"status":"ok","timestamp":1732889456515,"user_tz":-360,"elapsed":6,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["train_result = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"tdHNHUTIg6Bc","executionInfo":{"status":"ok","timestamp":1732891828314,"user_tz":-360,"elapsed":2371804,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"a643af48-613e-40bc-8f77-f0874a9365c8","collapsed":true},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:2314] 2024-11-29 14:10:54,711 >> ***** Running training *****\n","[INFO|trainer.py:2315] 2024-11-29 14:10:54,715 >>   Num examples = 4,920\n","[INFO|trainer.py:2316] 2024-11-29 14:10:54,725 >>   Num Epochs = 5\n","[INFO|trainer.py:2317] 2024-11-29 14:10:54,736 >>   Instantaneous batch size per device = 16\n","[INFO|trainer.py:2320] 2024-11-29 14:10:54,741 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:2321] 2024-11-29 14:10:54,743 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2322] 2024-11-29 14:10:54,756 >>   Total optimization steps = 1,540\n","[INFO|trainer.py:2323] 2024-11-29 14:10:54,759 >>   Number of trainable parameters = 177,855,747\n","[INFO|integration_utils.py:812] 2024-11-29 14:10:54,788 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1540' max='1540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1540/1540 39:19, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.554400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.275600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.150800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:2591] 2024-11-29 14:50:26,054 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]}]},{"cell_type":"code","source":["metrics = train_result.metrics\n","max_train_samples = (\n","    max_train_samples if max_train_samples is not None else len(train_dataset)\n",")\n","metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))"],"metadata":{"id":"BJcOpblsiGji","executionInfo":{"status":"ok","timestamp":1732891828315,"user_tz":-360,"elapsed":12,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["trainer.save_model()\n","trainer.log_metrics(\"train\", metrics)\n","trainer.save_metrics(\"train\", metrics)\n","trainer.save_state()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rk4wfUNaiIK6","executionInfo":{"status":"ok","timestamp":1732891831475,"user_tz":-360,"elapsed":3164,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"2217ca09-c14e-499a-8cd4-ec5b31a3c8c7"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:3812] 2024-11-29 14:50:26,125 >> Saving model checkpoint to ./bertBaseMultilingualNew/\n","[INFO|configuration_utils.py:414] 2024-11-29 14:50:26,131 >> Configuration saved in ./bertBaseMultilingualNew/config.json\n","[INFO|modeling_utils.py:3035] 2024-11-29 14:50:29,190 >> Model weights saved in ./bertBaseMultilingualNew/model.safetensors\n","[INFO|tokenization_utils_base.py:2646] 2024-11-29 14:50:29,198 >> tokenizer config file saved in ./bertBaseMultilingualNew/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2655] 2024-11-29 14:50:29,200 >> Special tokens file saved in ./bertBaseMultilingualNew/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        5.0\n","  total_flos               =  6028069GF\n","  train_loss               =      0.322\n","  train_runtime            = 0:39:31.33\n","  train_samples            =       4920\n","  train_samples_per_second =     10.374\n","  train_steps_per_second   =      0.649\n"]}]},{"cell_type":"code","source":["logger.info(\"*** Evaluate ***\")\n","\n","metrics = trainer.evaluate(eval_dataset=eval_dataset)\n","\n","max_eval_samples = (\n","    max_eval_samples if max_eval_samples is not None else len(eval_dataset)\n",")\n","metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n","\n","trainer.log_metrics(\"eval\", metrics)\n","trainer.save_metrics(\"eval\", metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"tnG5h4BHihC1","executionInfo":{"status":"ok","timestamp":1732891871683,"user_tz":-360,"elapsed":40217,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"ceef0784-af67-417f-e71c-918920ba34e6"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:4128] 2024-11-29 14:50:29,307 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4130] 2024-11-29 14:50:29,310 >>   Num examples = 1230\n","[INFO|trainer.py:4133] 2024-11-29 14:50:29,313 >>   Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [77/77 00:39]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        5.0\n","  eval_accuracy           =     0.8764\n","  eval_loss               =     0.5276\n","  eval_macro_f1           =     0.8771\n","  eval_macro_precision    =     0.8779\n","  eval_macro_recall       =     0.8768\n","  eval_runtime            = 0:00:39.79\n","  eval_samples            =       1230\n","  eval_samples_per_second =     30.906\n","  eval_steps_per_second   =      1.935\n"]}]},{"source":["# Assuming 'trainer' and 'eval_dataset' are defined as in your code\n","predictions = trainer.predict(eval_dataset)\n","predicted_labels = np.argmax(predictions.predictions, axis=1)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"wH1Py73Ta_Ww","executionInfo":{"status":"ok","timestamp":1732892205206,"user_tz":-360,"elapsed":41964,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"57a1e490-1b07-4844-90bb-c7774c41ef78"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:4128] 2024-11-29 14:56:01,499 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4130] 2024-11-29 14:56:01,502 >>   Num examples = 1230\n","[INFO|trainer.py:4133] 2024-11-29 14:56:01,504 >>   Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]},{"source":["from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Get true labels from the evaluation dataset\n","true_labels = predictions.label_ids\n","\n","# Generate the confusion matrix\n","cm = confusion_matrix(true_labels, predicted_labels)\n","\n","# Plot the confusion matrix using Seaborn\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.xlabel(\"Predicted Labels\")\n","plt.ylabel(\"True Labels\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549},"id":"1_WnzdIlbQVU","executionInfo":{"status":"ok","timestamp":1732892234318,"user_tz":-360,"elapsed":1581,"user":{"displayName":"Julkar Naeen","userId":"08957539261336131372"}},"outputId":"fc208aa7-e0d5-43bf-90cc-c9c1889c4ec0"},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x700 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}